{"cells":[{"attachments":{},"cell_type":"markdown","metadata":{"id":"jyX8LLE2D2io"},"source":["### import"]},{"cell_type":"code","execution_count":34,"metadata":{"executionInfo":{"elapsed":3772,"status":"ok","timestamp":1678981510929,"user":{"displayName":"김기열","userId":"17328396237407385166"},"user_tz":-540},"id":"aT_yvQvO4ldz"},"outputs":[],"source":["import torch\n","from torch import nn\n","from torch.nn import functional\n","from torch import optim\n","from torch.utils.data import random_split\n","\n","from torchvision.datasets import FashionMNIST \n","from torchvision import transforms as tr\n","\n","import os\n","import sys\n","import numpy as np\n","from tqdm import tqdm # train할때 progress bar를 보여줌\n","import matplotlib.pyplot as plt"]},{"cell_type":"code","execution_count":35,"metadata":{},"outputs":[],"source":["project_root = 'C:/Users/rlduf/.vscode/study/DeepLearning'\n","sys.path.append(project_root)"]},{"cell_type":"code","execution_count":36,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":3,"status":"ok","timestamp":1678982390545,"user":{"displayName":"김기열","userId":"17328396237407385166"},"user_tz":-540},"id":"RMpjTNP_5y27","outputId":"a4e7025d-8a37-445d-d438-67e48d2b899a"},"outputs":[],"source":["# os.getcwd() -> 현재 경로\n","data_root = os.path.join(os.getcwd(), 'data') # 현재 경로에서 data_root 경로를 지정"]},{"attachments":{},"cell_type":"markdown","metadata":{"id":"FaDCqx5YD60r"},"source":["### Preprocessing & Dataset"]},{"cell_type":"code","execution_count":37,"metadata":{"executionInfo":{"elapsed":2,"status":"ok","timestamp":1678982391288,"user":{"displayName":"김기열","userId":"17328396237407385166"},"user_tz":-540},"id":"Pc3O_TU06Hrq"},"outputs":[],"source":["transform = tr.Compose( \n","    [\n","        tr.ToTensor(), # PIL Image나 NumPy ndarray 를 FloatTensor 로 변환하고, 이미지의 픽셀의 크기(intensity) 값을 [0., 1.] 범위로 비례하여 조정(scale)\n","        tr.Normalize([0.5], [0.5]) # Normalize a tensor image with mean and standard deviation\n","    ]\n",")\n","\n","fashion_mnist_dataset = FashionMNIST(data_root, download=True, train=True, transform=transform) "]},{"cell_type":"code","execution_count":38,"metadata":{"executionInfo":{"elapsed":3,"status":"ok","timestamp":1678982392420,"user":{"displayName":"김기열","userId":"17328396237407385166"},"user_tz":-540},"id":"J4urrfgV_i9j"},"outputs":[],"source":["# torch.utils.data.random_split을 사용할 수 있음\n","# 하지만 이 방법은 label의 비율을 고려하지 않았기 때문에 정확도가 떨어질 수 있음\n","# 따라서 data_utils.py 파일의 dataset_split 함수 import\n","from data_utils import dataset_split "]},{"cell_type":"code","execution_count":39,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":3,"status":"ok","timestamp":1678982392420,"user":{"displayName":"김기열","userId":"17328396237407385166"},"user_tz":-540},"id":"w_IgCbJhCHAN","outputId":"5878eacd-af97-47ce-a2e7-88b7d15b7c38"},"outputs":[{"name":"stdout","output_type":"stream","text":["{'train': <torch.utils.data.dataset.Subset object at 0x000001E6151ADFC8>, 'val': <torch.utils.data.dataset.Subset object at 0x000001E6151ADC08>}\n"]}],"source":["dataset = dataset_split(fashion_mnist_dataset, split=[0.9, 0.1])\n","print(dataset) # dict 형태"]},{"cell_type":"code","execution_count":40,"metadata":{"executionInfo":{"elapsed":2,"status":"ok","timestamp":1678982392421,"user":{"displayName":"김기열","userId":"17328396237407385166"},"user_tz":-540},"id":"NhrkLBmICZMM"},"outputs":[],"source":["train_dataset = dataset['train']\n","val_dataset = dataset['val']\n","\n","train_batch_size = 128\n","val_batch_size = 32"]},{"attachments":{},"cell_type":"markdown","metadata":{"id":"c5kTOVs3D_L1"},"source":["### DataLoader"]},{"cell_type":"code","execution_count":41,"metadata":{"executionInfo":{"elapsed":2,"status":"ok","timestamp":1678982394015,"user":{"displayName":"김기열","userId":"17328396237407385166"},"user_tz":-540},"id":"MtFLN4PgCrf7"},"outputs":[],"source":["train_dataloader = torch.utils.data.DataLoader(\n","    train_dataset, batch_size=train_batch_size, shuffle=True, num_workers=1 # num_workers는 병렬처리할 때 사용\n",")\n","\n","val_dataloader = torch.utils.data.DataLoader(\n","    val_dataset, batch_size=val_batch_size, shuffle=False, num_workers=1\n",")"]},{"attachments":{},"cell_type":"markdown","metadata":{"id":"2iC7iQRgEiWp"},"source":["### Model"]},{"cell_type":"code","execution_count":42,"metadata":{"executionInfo":{"elapsed":4,"status":"ok","timestamp":1678982395053,"user":{"displayName":"김기열","userId":"17328396237407385166"},"user_tz":-540},"id":"NdMXaa8gEiFa"},"outputs":[],"source":["class MLP(nn.Module):\n","    def __init__(self, in_dim, h1_dim, h2_dim, out_dim):\n","        super(MLP, self).__init__()\n","        self.linear1 = nn.Linear(in_dim, h1_dim)\n","        self.linear2 = nn.Linear(h1_dim, h2_dim)\n","        self.linear3 = nn.Linear(h2_dim, out_dim)\n","\n","    def forward(self, input):\n","        x = torch.flatten(input, start_dim = 1)\n","        # forward method에서 사용할거면 nn.functional.relu를 사용 / nn.Sequential 안에 사용할거면 nn.ReLU()를 사용\n","        x = functional.relu(self.linear1(x))\n","        x = functional.relu(self.linear2(x))\n","        out = self.linear3(x)\n","        return out"]},{"attachments":{},"cell_type":"markdown","metadata":{"id":"iV8GAY0nJIpc"},"source":["### Loss Fucntion, Optimization, Tensorboard"]},{"cell_type":"code","execution_count":43,"metadata":{},"outputs":[{"data":{"text/plain":["'cuda'"]},"execution_count":43,"metadata":{},"output_type":"execute_result"}],"source":["device = 'cuda' if torch.cuda.is_available() else 'cpu'\n","device"]},{"cell_type":"code","execution_count":44,"metadata":{"executionInfo":{"elapsed":4,"status":"ok","timestamp":1678982395054,"user":{"displayName":"김기열","userId":"17328396237407385166"},"user_tz":-540},"id":"TaXYrH_fJSSD"},"outputs":[],"source":["# model\n","model = MLP(28*28, 128, 64, 10).to(device)\n","\n","# define loss\n","loss_function = nn.CrossEntropyLoss()\n","\n","# define optimizer\n","optimizer = torch.optim.Adam(model.parameters(), lr=1e-3)\n","max_epoch = 10"]},{"cell_type":"code","execution_count":45,"metadata":{},"outputs":[{"name":"stderr","output_type":"stream","text":["validation: 100%|██████████| 188/188 [00:04<00:00, 42.59it/s] \n"]},{"name":"stdout","output_type":"stream","text":["epoch:1 -> val_loss:2.325981  val_acc:0.09066666662693024\n"]},{"name":"stderr","output_type":"stream","text":["training:   0%|          | 0/422 [00:01<?, ?it/s]\n"]},{"ename":"NameError","evalue":"name 'log_interval' is not defined","output_type":"error","traceback":["\u001b[1;31m---------------------------------------------------------------------------\u001b[0m","\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)","\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_16096\\3360390665.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     57\u001b[0m         \u001b[0mcurrent_corrects\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msum\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpreds\u001b[0m \u001b[1;33m==\u001b[0m \u001b[0mlabels\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;31m# 두 텐서를 비교하여 bool 형태로 텐서를 만든 후 torch.sum을 하면 true를 모두 더함\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     58\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 59\u001b[1;33m         \u001b[1;32mif\u001b[0m \u001b[0mtrain_step\u001b[0m \u001b[1;33m%\u001b[0m \u001b[0mlog_interval\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     60\u001b[0m             \u001b[0mtrain_loss\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcurrent_loss\u001b[0m \u001b[1;33m/\u001b[0m \u001b[0mlog_interval\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     61\u001b[0m             \u001b[0mtrain_acc\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcurrent_corrects\u001b[0m \u001b[1;33m/\u001b[0m \u001b[0mlog_interval\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n","\u001b[1;31mNameError\u001b[0m: name 'log_interval' is not defined"]}],"source":["# do train with validation.\n","train_step = 0\n","for epoch in range(1, max_epoch+1):\n","    # valid step\n","    with torch.no_grad():\n","        val_loss = 0.0\n","        val_corrects = 0\n","        model.eval()\n","\n","        for val_batch_idx, (val_images, val_labels) in enumerate(\n","            tqdm(val_dataloader, position=0, leave=True, desc=\"validation\")\n","        ):\n","            val_images, val_labels = val_images.to(device), val_labels.to(device)\n","            # forward\n","            val_outputs = model(val_images)\n","            _, val_preds = torch.max(val_outputs, 1)\n","            \n","            # loss & acc\n","            val_loss += loss_function(val_outputs, val_labels) / val_outputs.shape[0]\n","            val_corrects += torch.sum(val_preds == val_labels.data) / val_outputs.shape[0]\n","    \n","    # valid step logging\n","    val_epoch_loss = val_loss / len(val_dataloader)\n","    val_epoch_acc = val_corrects / len(val_dataloader)\n","    \n","    print(\n","        f\"{epoch} epoch, {train_step} step: val_loss: {val_epoch_loss}, val_acc: {val_epoch_acc}\\n\"\n","    )\n","\n","    # check model early stopping point & save model if the model reached the best performance.\n","    early_stopper(val_epoch_loss, model)\n","    if early_stopper.early_stop:\n","        break\n","    \n","    # train step\n","    current_loss = 0\n","    current_corrects = 0\n","    model.train()\n","\n","    for batch_idx, (images, labels) in enumerate(\n","         tqdm(train_dataloader, position=0, leave=True, desc=\"training\")\n","    ):\n","        current_loss = 0.0\n","        current_corrects = 0\n","\n","        # Forward\n","        # get predictions\n","        images, labels = images.to(device), labels.to(device)\n","        outputs = model(images)\n","        _, preds = torch.max(outputs, 1)\n","        \n","        # get loss (Loss 계산)\n","        loss = loss_function(outputs, labels)\n","\n","        # Backpropagation\n","        # optimizer 초기화 (zero화)\n","        optimizer.zero_grad()\n","\n","        # Perform backward pass\n","        loss.backward()\n","\n","        # Perform Optimization\n","        optimizer.step()\n","\n","        current_loss += loss.item()\n","        current_corrects += torch.sum(preds == labels.data)\n","\n","        if train_step % 100 == 0:\n","            train_loss = current_loss / 100\n","            train_acc = current_corrects / 100\n","\n","            print(\n","                f\"{train_step}: train_loss: {train_loss}, train_acc: {train_acc}\"\n","            )\n","            current_loss = 0\n","            current_corrects = 0\n","\n","        train_step += 1\n","\n","    print('\\n')"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":1991,"status":"ok","timestamp":1678982877943,"user":{"displayName":"김기열","userId":"17328396237407385166"},"user_tz":-540},"id":"eEIapFtKK0fo"},"outputs":[],"source":["# save model\n","os.makedirs(\"C:/Users/rlduf/.vscode/study/DeepLearning/logs/models\", exist_ok=True)\n","torch.save(model, \"C:/Users/rlduf/.vscode/study/DeepLearning/logs/models/MLP.ckpt\")"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":378,"status":"ok","timestamp":1678982893908,"user":{"displayName":"김기열","userId":"17328396237407385166"},"user_tz":-540},"id":"csGwcSK3K2Cf","outputId":"67a60055-a71f-460c-cfdc-515d8eb27d94"},"outputs":[],"source":["# load model\n","loaded_model = torch.load(\"C:/Users/rlduf/.vscode/study/DeepLearning/logs/models/MLP.ckpt\")\n","loaded_model.eval()\n","print(loaded_model)"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":2,"status":"ok","timestamp":1678982897780,"user":{"displayName":"김기열","userId":"17328396237407385166"},"user_tz":-540},"id":"umUQlFIRK3Bm"},"outputs":[],"source":["def softmax(x, axis=0):\n","    \"numpy softmax\"\n","    max = np.max(x, axis=axis, keepdims=True)\n","    e_x = np.exp(x - max)\n","    sum = np.sum(e_x, axis=axis, keepdims=True)\n","    f_x = e_x / sum\n","    return f_x"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":2252,"status":"ok","timestamp":1678983054878,"user":{"displayName":"김기열","userId":"17328396237407385166"},"user_tz":-540},"id":"BD12HbP0K4lW","outputId":"1ada661b-3087-463f-cbf7-08f9fca2ea84"},"outputs":[],"source":["test_batch_size = 100\n","test_dataset = FashionMNIST(data_root, download=True, train=False, transform=transforms.ToTensor())\n","test_dataloader = torch.utils.data.DataLoader(test_dataset, batch_size=test_batch_size, shuffle=False, num_workers=1)\n","\n","test_labels_list = []\n","test_preds_list = []\n","test_outputs_list = []\n","\n","for i, (test_images, test_labels) in enumerate(tqdm(test_dataloader, position=0, leave=True, desc=\"testing\")):\n","    # forward\n","    test_images, test_labels = test_images.to(device), test_labels.to(device)\n","    test_outputs = loaded_model(test_images)\n","    _, test_preds = torch.max(test_outputs, 1)\n","\n","    final_outs = softmax(test_outputs.detach().cpu().numpy(), axis=1)\n","    test_outputs_list.extend(final_outs)\n","    test_preds_list.extend(test_preds.detach().cpu().numpy())\n","    test_labels_list.extend(test_labels.detach().cpu().numpy())\n","\n","# sklearn library의 성능 평가를 위해 ndarray로 변환\n","test_preds_list = np.array(test_preds_list)\n","test_labels_list = np.array(test_labels_list)\n","\n","print(f\"\\nacc: {np.mean(test_preds_list == test_labels_list)*100}%\")"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":313},"executionInfo":{"elapsed":1970,"status":"ok","timestamp":1678982987588,"user":{"displayName":"김기열","userId":"17328396237407385166"},"user_tz":-540},"id":"fT7Qd2i7K765","outputId":"2ab108d9-66ba-4dcb-8810-15a67db1ebe2"},"outputs":[],"source":["# ROC Curve\n","from sklearn.metrics import roc_curve\n","from sklearn.metrics import roc_auc_score\n","\n","fpr = {}\n","tpr = {}\n","thresh = {}\n","n_class = 10\n","\n","for i in range(n_class):\n","    fpr[i], tpr[i], thresh[i] = roc_curve(test_labels_list, np.array(test_outputs_list)[:, i], pos_label=i)\n","\n","# plot.\n","for i in range(n_class):\n","    plt.plot(fpr[i], tpr[i], linestyle=\"--\", label=f\"Class {i} vs Rest\")\n","plt.title(\"Multi-class ROC Curve\")\n","plt.xlabel(\"False Positive Rate\")\n","plt.ylabel(\"True Positive Rate\")\n","plt.legend(loc=\"best\")\n","plt.show()\n","\n","print(\"auc_score\", roc_auc_score(test_labels_list, test_outputs_list, multi_class=\"ovo\", average=\"macro\"))"]}],"metadata":{"accelerator":"GPU","colab":{"authorship_tag":"ABX9TyMIGilqpmQfURRp6ZgL9RYL","provenance":[]},"gpuClass":"standard","kernelspec":{"display_name":"jupyter_notebook","language":"python","name":"deeplearning"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.16"}},"nbformat":4,"nbformat_minor":0}
