{"cells":[{"attachments":{},"cell_type":"markdown","metadata":{"id":"NzHP2rndF-0G"},"source":["### import"]},{"cell_type":"code","execution_count":1,"metadata":{"id":"Mi95dewjGeW_"},"outputs":[],"source":["import os\n","import sys\n","from datetime import datetime\n","\n","project_root = \"C:/Users/rlduf/.vscode/study/DeepLearning\"\n","sys.path.append(project_root)"]},{"cell_type":"code","execution_count":3,"metadata":{"id":"YD7vyST9GdHv"},"outputs":[],"source":["import numpy as np\n","from tqdm import tqdm\n","import matplotlib.pyplot as plt\n","from omegaconf import OmegaConf\n","from omegaconf import DictConfig\n","\n","import torch\n","from torch import nn\n","import torch.nn.functional as F\n","from torch import optim\n","from torch_optimizer import RAdam\n","from torch_optimizer import AdamP\n","from torch.utils.tensorboard import SummaryWriter\n","from torch.utils.data import random_split\n","from torchvision.datasets import FashionMNIST\n","from torchvision import transforms\n","import wandb\n","\n","from efficientnet_pytorch import EfficientNet"]},{"cell_type":"code","execution_count":4,"metadata":{"id":"QX3soatAMk5B"},"outputs":[],"source":["from data_utils import dataset_split"]},{"cell_type":"code","execution_count":5,"metadata":{"id":"lISGUqfUG_Ny"},"outputs":[],"source":["data_root = os.path.join(os.getcwd(), \"data\")\n","\n","# 전처리 부분 (preprocessing) & 데이터 셋 정의.\n","# transform = transforms.Compose(\n","#     [\n","#         transforms.ToTensor(),\n","#         transforms.Normalize([0.5], [0.5]), # mean, # std\n","#     ]\n","# )\n","\n","transform = transforms.Compose(\n","    [\n","        transforms.Resize(224),\n","        transforms.ToTensor(),\n","        transforms.Lambda(lambda x: x.repeat(3, 1, 1)),\n","        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225]),\n","    ]\n",")\n","\n","fashion_mnist_dataset = FashionMNIST(data_root, download=True, train=True, transform=transform)\n"]},{"attachments":{},"cell_type":"markdown","metadata":{"id":"0waoPp23NcE0"},"source":["### dataloader"]},{"cell_type":"code","execution_count":6,"metadata":{"id":"A5Nq1tZiJ84g"},"outputs":[],"source":["datasets = dataset_split(fashion_mnist_dataset, split=[0.9, 0.1])\n","\n","train_dataset = datasets[\"train\"]\n","val_dataset = datasets[\"val\"]\n","\n","train_batch_size = 100\n","val_batch_size = 10\n","\n","train_dataloader = torch.utils.data.DataLoader(\n","    train_dataset, batch_size=train_batch_size, shuffle=True, num_workers=1\n",")\n","val_dataloader = torch.utils.data.DataLoader(\n","    val_dataset, batch_size=val_batch_size, shuffle=False, num_workers=1\n",")"]},{"attachments":{},"cell_type":"markdown","metadata":{"id":"Lwd5nW_3N37z"},"source":["### model\n"]},{"cell_type":"code","execution_count":7,"metadata":{"id":"-O--VMLMN04F"},"outputs":[],"source":["# Define Model.\n","\n","class MLP(nn.Module):\n","    def __init__(self, in_dim: int, h1_dim: int, h2_dim: int, out_dim: int):\n","        super().__init__()\n","        self.linear1 = nn.Linear(in_dim, h1_dim)\n","        self.linear2 = nn.Linear(h1_dim, h2_dim)\n","        self.linear3 = nn.Linear(h2_dim, out_dim)\n","        self.relu = F.relu\n","        pass\n","    \n","    def forward(self, input):\n","        x = torch.flatten(input, start_dim=1)\n","        x = self.relu(self.linear1(x))\n","        x = self.relu(self.linear2(x))\n","        out = self.linear3(x)\n","        # out = F.softmax(out)\n","        return out\n","\n","class MLPWithDropout(MLP):\n","    def __init__(self, in_dim: int, h1_dim: int, h2_dim: int, out_dim: int, dropout_prob: float):\n","        super().__init__(in_dim, h1_dim, h2_dim, out_dim)\n","        self.dropout1 = nn.Dropout(dropout_prob)\n","        self.dropout2 = nn.Dropout(dropout_prob)\n","    \n","    def forward(self, input):\n","        x = torch.flatten(input, start_dim=1)\n","        x = self.relu(self.linear1(x))\n","        x = self.dropout1(x)\n","        x = self.relu(self.linear2(x))\n","        x = self.dropout2(x)\n","        out = self.linear3(x)\n","        # out = F.softmax(out)\n","        return out\n"]},{"attachments":{},"cell_type":"markdown","metadata":{"id":"42in1xpAqQDY"},"source":["### CNN"]},{"cell_type":"code","execution_count":8,"metadata":{"id":"dCEx_VgEqTiB"},"outputs":[{"name":"stdout","output_type":"stream","text":["layer_1:\n","  conv2d_in_channels: 1\n","  conv2d_out_channels: 32\n","  conv2d_kernel_size: 3\n","  conv2d_padding: 1\n","  maxpool2d_kernel_size: 2\n","  maxpool2d_stride: 2\n","layer_2:\n","  conv2d_in_channels: 32\n","  conv2d_out_channels: 64\n","  conv2d_kernel_size: 3\n","  conv2d_padding: 0\n","  maxpool2d_kernel_size: 2\n","  maxpool2d_stride: 1\n","fc_1:\n","  in_features: 2304\n","  out_features: 512\n","fc_2:\n","  in_features: 512\n","  out_features: 128\n","fc_3:\n","  in_features: 128\n","  out_features: 10\n","dropout_prob: 0.25\n","\n"]}],"source":["_cnn_cfg_dict: dict = {\n","    \"layer_1\": {\n","        \"conv2d_in_channels\": 1,\n","        \"conv2d_out_channels\": 32,\n","        \"conv2d_kernel_size\": 3,\n","        \"conv2d_padding\": 1,\n","        \"maxpool2d_kernel_size\": 2,\n","        \"maxpool2d_stride\": 2,\n","    },\n","    \"layer_2\": {\n","        \"conv2d_in_channels\": 32,\n","        \"conv2d_out_channels\": 64,\n","        \"conv2d_kernel_size\": 3,\n","        \"conv2d_padding\": 0,\n","        \"maxpool2d_kernel_size\": 2,\n","        \"maxpool2d_stride\": 1,\n","    },\n","    \"fc_1\": {\n","        \"in_features\": 2304, #  수정 필요!\n","        \"out_features\": 512,\n","    },\n","    \"fc_2\": {\n","        \"in_features\": 512,\n","        \"out_features\": 128,        \n","    },\n","    \"fc_3\": {\n","        \"in_features\": 128,\n","        \"out_features\": 10,\n","    },\n","    \"dropout_prob\": 0.25,\n","}\n","_cnn_cfg = OmegaConf.create(_cnn_cfg_dict)\n","print(OmegaConf.to_yaml(_cnn_cfg))\n","\n","class CNN(nn.Module):\n","    def __init__(self, cfg: DictConfig = _cnn_cfg):\n","        super().__init__()\n","        self.layer1 = nn.Sequential(\n","            nn.Conv2d(\n","                in_channels=cfg.layer_1.conv2d_in_channels,\n","                out_channels=cfg.layer_1.conv2d_out_channels,\n","                kernel_size=cfg.layer_1.conv2d_kernel_size,\n","                padding=cfg.layer_1.conv2d_padding\n","            ),\n","            nn.BatchNorm2d(cfg.layer_1.conv2d_out_channels),\n","            nn.ReLU(),\n","            nn.MaxPool2d(\n","                kernel_size=cfg.layer_1.maxpool2d_kernel_size,\n","                stride=cfg.layer_1.maxpool2d_kernel_size\n","            )\n","        )\n","        self.layer2 = nn.Sequential(\n","            nn.Conv2d(\n","                in_channels=cfg.layer_2.conv2d_in_channels,\n","                out_channels=cfg.layer_2.conv2d_out_channels,\n","                kernel_size=cfg.layer_2.conv2d_kernel_size,\n","                padding=cfg.layer_2.conv2d_padding\n","            ),\n","            nn.BatchNorm2d(cfg.layer_2.conv2d_out_channels),\n","            nn.ReLU(),\n","            nn.MaxPool2d(\n","                kernel_size=cfg.layer_2.maxpool2d_kernel_size,\n","                stride=cfg.layer_2.maxpool2d_kernel_size\n","            )\n","        )\n","        self.fc1 = nn.Linear(\n","            in_features=cfg.fc_1.in_features,\n","            out_features=cfg.fc_1.out_features,\n","        )\n","        self.fc2 = nn.Linear(\n","            in_features=cfg.fc_2.in_features,\n","            out_features=cfg.fc_2.out_features,\n","        )\n","        self.fc3 = nn.Linear(\n","            in_features=cfg.fc_3.in_features,\n","            out_features=cfg.fc_3.out_features,\n","        )\n","        self.dropout = nn.Dropout2d(cfg.dropout_prob)\n","\n","\n","    def forward(self, x):\n","        out = self.layer1(x)\n","        out = self.layer2(out)\n","        out = out.view(out.size(0), -1)\n","        out = self.fc1(out)\n","        out = self.dropout(out)\n","        out = self.fc2(out)\n","        out = self.fc3(out)\n","        return out\n"]},{"cell_type":"code","execution_count":9,"metadata":{"id":"HVNk_qol3eCz"},"outputs":[{"name":"stdout","output_type":"stream","text":["efficient_net_model_name: efficientnet-b1\n","num_classes: 10\n","\n"]}],"source":["_efficient_finetune_cfg_dict: dict = {\n","    \"efficient_net_model_name\": \"efficientnet-b1\",\n","    \"num_classes\": 10\n","}\n","_efficient_finetune_cfg_cfg = OmegaConf.create(_efficient_finetune_cfg_dict)\n","print(OmegaConf.to_yaml(_efficient_finetune_cfg_cfg))\n","\n","class EfficientNetFinetune(nn.Module):\n","    def __init__(self, cfg: DictConfig = _efficient_finetune_cfg_cfg):\n","        super().__init__()\n","        self.efficientnet = EfficientNet.from_pretrained(\n","            cfg.efficient_net_model_name,\n","            cfg.num_classes\n","        )\n","        self.efficientnet\n","    \n","    def forward(self, x):\n","        out = self.efficientnet(x)\n","        return out"]},{"attachments":{},"cell_type":"markdown","metadata":{"id":"tMM1y75wql8f"},"source":["### Learning Rate Scheduler \n","\n"]},{"cell_type":"code","execution_count":10,"metadata":{"id":"3y1m5T3-qqCk"},"outputs":[],"source":["# Warmup Scheduler\n","class WarmupLR(optim.lr_scheduler.LambdaLR):\n","\n","    def __init__(\n","        self,\n","        optimizer: optim.Optimizer,\n","        warmup_end_steps: int,\n","        last_epoch: int = -1,\n","    ):\n","        \n","        def wramup_fn(step: int):\n","            if step < warmup_end_steps:\n","                return float(step) / float(max(warmup_end_steps, 1))\n","            return 1.0\n","        \n","        super().__init__(optimizer, wramup_fn, last_epoch)\n"]},{"attachments":{},"cell_type":"markdown","metadata":{"id":"b8tljBSaQBZB"},"source":["### model, optimizer, loss function, logger"]},{"cell_type":"code","execution_count":13,"metadata":{"id":"z8p_hsjsO-on"},"outputs":[{"name":"stdout","output_type":"stream","text":["Loaded pretrained weights for efficientnet-b1\n"]},{"data":{"text/html":["Finishing last run (ID:qek6zoqf) before initializing another..."],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"fc40a759a826454ba43b42c4e5e0b936","version_major":2,"version_minor":0},"text/plain":["VBox(children=(Label(value='0.001 MB of 0.001 MB uploaded (0.000 MB deduped)\\r'), FloatProgress(value=1.0, max…"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":[" View run <strong style=\"color:#cdcd00\">EfficientNetFinetune-RAdam_optim_0.001_lr_with_no_scheduler</strong> at: <a href='https://wandb.ai/rlduf422/fashion_mnist/runs/qek6zoqf' target=\"_blank\">https://wandb.ai/rlduf422/fashion_mnist/runs/qek6zoqf</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["Find logs at: <code>.\\wandb\\run-20230331_002633-qek6zoqf\\logs</code>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["Successfully finished last run (ID:qek6zoqf). Initializing new run:<br/>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"39b5f2e7c01b40169af18da0f8c939c2","version_major":2,"version_minor":0},"text/plain":["VBox(children=(Label(value='Waiting for wandb.init()...\\r'), FloatProgress(value=0.016666666666666666, max=1.0…"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["Tracking run with wandb version 0.14.0"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["Run data is saved locally in <code>c:\\Users\\rlduf\\.vscode\\study\\DeepLearning\\CNN\\wandb\\run-20230331_002901-48ds5k9q</code>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["Syncing run <strong><a href='https://wandb.ai/rlduf422/fashion_mnist/runs/48ds5k9q' target=\"_blank\">EfficientNetFinetune-RAdam_optim_0.001_lr_with_no_scheduler</a></strong> to <a href='https://wandb.ai/rlduf422/fashion_mnist' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":[" View project at <a href='https://wandb.ai/rlduf422/fashion_mnist' target=\"_blank\">https://wandb.ai/rlduf422/fashion_mnist</a>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":[" View run at <a href='https://wandb.ai/rlduf422/fashion_mnist/runs/48ds5k9q' target=\"_blank\">https://wandb.ai/rlduf422/fashion_mnist/runs/48ds5k9q</a>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"}],"source":["# gpu setup\n","# gpu = None\n","gpu = 0\n","\n","# define model.\n","# model = MLP(28*28, 128, 64, 10)\n","# model = MLPWithDropout(28*28, 128, 64, 10, dropout_prob=0.3)\n","# model = CNN(cfg=_cnn_cfg)\n","model = EfficientNetFinetune(cfg=_efficient_finetune_cfg_cfg)\n","\n","if gpu is not None:\n","    model.cuda(gpu)\n","model_name = type(model).__name__\n","\n","# define loss\n","loss_function = nn.CrossEntropyLoss()\n","\n","# define optimizer\n","lr = 1e-3\n","# optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n","# optimizer = torch.optim.SGD(model.parameters(), lr=lr)\n","optimizer = RAdam(model.parameters(), lr=lr)\n","# optimizer = AdamP(model.parameters(), lr=lr)\n","optimizer_name = type(optimizer).__name__\n","\n","# define scheduler\n","scheduler = None\n","# scheduler = WarmupLR(optimizer, 1500)\n","scheduler_name = type(scheduler).__name__ if scheduler is not None else \"no\"\n","\n","max_epoch = 30\n","\n","# define tensorboard logger\n","run_name = f\"{model_name}-{optimizer_name}_optim_{lr}_lr_with_{scheduler_name}_scheduler\"\n","log_dir = os.path.join(project_root, \"runs\", run_name)\n","writer = SummaryWriter(log_dir=log_dir)\n","log_interval = 100\n","\n","# define wandb\n","project_name = \"fashion_mnist\"\n","run_tags = [project_name]\n","wandb.init(\n","    project=project_name,\n","    name=run_name,\n","    tags=run_tags,\n","    config={\"lr\": lr, \"model_name\": model_name, \"optimizer_name\": optimizer_name, \"scheduler_name\": scheduler_name},\n","    reinit=True,\n",")\n","wandb.watch(model)\n","\n","# set save model path\n","log_model_path = os.path.join(log_dir, \"models\")\n","os.makedirs(log_model_path, exist_ok=True)\n"]},{"attachments":{},"cell_type":"markdown","metadata":{"id":"lnGxA90KyyUi"},"source":["### Early Stopping callback Object Class"]},{"cell_type":"code","execution_count":15,"metadata":{"id":"WyuzST93ynLE"},"outputs":[],"source":["# With some modifications, source is from https://github.com/Bjarten/early-stopping-pytorch\n","\n","class EarlyStopping:\n","    \"\"\"Early stops the training if validation loss doesn't improve after a given patience.\"\"\"\n","    def __init__(self, patience=7, verbose=False, delta=0, path='checkpoint.ckpt', trace_func=print):\n","        \"\"\"\n","        Args:\n","            patience (int): How long to wait after last time validation loss improved.\n","                            Default: 7\n","            verbose (bool): If True, prints a message for each validation loss improvement. \n","                            Default: False\n","            delta (float): Minimum change in the monitored quantity to qualify as an improvement.\n","                            Default: 0\n","            path (str): Path for the checkpoint to be saved to.\n","                            Default: 'checkpoint.ckpt'\n","            trace_func (function): trace print function.\n","                            Default: print            \n","        \"\"\"\n","        self.patience = patience\n","        self.verbose = verbose\n","        self.counter = 0\n","        self.best_score = None\n","        self.early_stop = False\n","        self.val_loss_min = np.Inf\n","        self.delta = delta\n","        self.path = path\n","        self.trace_func = trace_func\n","\n","    def __call__(self, val_loss, model):\n","\n","        score = -val_loss\n","\n","        if self.best_score is None:\n","            self.best_score = score\n","            self.save_checkpoint(val_loss, model)\n","        elif score < self.best_score + self.delta:\n","            self.counter += 1\n","            self.trace_func(f'EarlyStopping counter: {self.counter} out of {self.patience}')\n","            if self.counter >= self.patience:\n","                self.early_stop = True\n","        else:\n","            self.best_score = score\n","            self.save_checkpoint(val_loss, model)\n","            self.counter = 0\n","\n","    def save_checkpoint(self, val_loss, model):\n","        '''Saves model when validation loss decrease.'''\n","        if self.verbose:\n","            self.trace_func(f'Validation loss decreased ({self.val_loss_min:.6f} --> {val_loss:.6f}).  Saving model ...')\n","        \n","        filename = self.path.split('/')[-1]\n","        save_dir = os.path.dirname(self.path)\n","        torch.save(model, os.path.join(save_dir, f\"val_loss-{val_loss}-{filename}\"))\n","        self.val_loss_min = val_loss"]},{"cell_type":"code","execution_count":16,"metadata":{"id":"oq-XpcGXQu1v"},"outputs":[{"name":"stderr","output_type":"stream","text":["validation:   0%|          | 0/600 [00:00<?, ?it/s]\n"]},{"ename":"PicklingError","evalue":"Can't pickle <function <lambda> at 0x000001BA32EAB168>: attribute lookup <lambda> on __main__ failed","output_type":"error","traceback":["\u001b[1;31m---------------------------------------------------------------------------\u001b[0m","\u001b[1;31mPicklingError\u001b[0m                             Traceback (most recent call last)","\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_15020\\4092640783.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     14\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     15\u001b[0m         for val_batch_idx, (val_images, val_labels) in enumerate(\n\u001b[1;32m---> 16\u001b[1;33m             \u001b[0mtqdm\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mval_dataloader\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mposition\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mleave\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdesc\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"validation\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     17\u001b[0m         ):\n\u001b[0;32m     18\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mgpu\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n","\u001b[1;32mc:\\Users\\rlduf\\anaconda3\\envs\\deeplearning\\lib\\site-packages\\tqdm\\std.py\u001b[0m in \u001b[0;36m__iter__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1176\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1177\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1178\u001b[1;33m             \u001b[1;32mfor\u001b[0m \u001b[0mobj\u001b[0m \u001b[1;32min\u001b[0m \u001b[0miterable\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1179\u001b[0m                 \u001b[1;32myield\u001b[0m \u001b[0mobj\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1180\u001b[0m                 \u001b[1;31m# Update and possibly print the progressbar.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n","\u001b[1;32mc:\\Users\\rlduf\\anaconda3\\envs\\deeplearning\\lib\\site-packages\\torch\\utils\\data\\dataloader.py\u001b[0m in \u001b[0;36m__iter__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    433\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_iterator\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    434\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 435\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_get_iterator\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    436\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    437\u001b[0m     \u001b[1;33m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n","\u001b[1;32mc:\\Users\\rlduf\\anaconda3\\envs\\deeplearning\\lib\\site-packages\\torch\\utils\\data\\dataloader.py\u001b[0m in \u001b[0;36m_get_iterator\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    379\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    380\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcheck_worker_number_rationality\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 381\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0m_MultiProcessingDataLoaderIter\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    382\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    383\u001b[0m     \u001b[1;33m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n","\u001b[1;32mc:\\Users\\rlduf\\anaconda3\\envs\\deeplearning\\lib\\site-packages\\torch\\utils\\data\\dataloader.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, loader)\u001b[0m\n\u001b[0;32m   1032\u001b[0m             \u001b[1;31m#     before it starts, and __del__ tries to join but will get:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1033\u001b[0m             \u001b[1;31m#     AssertionError: can only join a started process.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1034\u001b[1;33m             \u001b[0mw\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstart\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1035\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_index_queues\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mindex_queue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1036\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_workers\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mw\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n","\u001b[1;32mc:\\Users\\rlduf\\anaconda3\\envs\\deeplearning\\lib\\multiprocessing\\process.py\u001b[0m in \u001b[0;36mstart\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    110\u001b[0m                \u001b[1;34m'daemonic processes are not allowed to have children'\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    111\u001b[0m         \u001b[0m_cleanup\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 112\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_popen\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_Popen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    113\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_sentinel\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_popen\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msentinel\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    114\u001b[0m         \u001b[1;31m# Avoid a refcycle if the target function holds an indirect\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n","\u001b[1;32mc:\\Users\\rlduf\\anaconda3\\envs\\deeplearning\\lib\\multiprocessing\\context.py\u001b[0m in \u001b[0;36m_Popen\u001b[1;34m(process_obj)\u001b[0m\n\u001b[0;32m    221\u001b[0m     \u001b[1;33m@\u001b[0m\u001b[0mstaticmethod\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    222\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_Popen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mprocess_obj\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 223\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0m_default_context\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_context\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mProcess\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_Popen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mprocess_obj\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    224\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    225\u001b[0m \u001b[1;32mclass\u001b[0m \u001b[0mDefaultContext\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mBaseContext\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n","\u001b[1;32mc:\\Users\\rlduf\\anaconda3\\envs\\deeplearning\\lib\\multiprocessing\\context.py\u001b[0m in \u001b[0;36m_Popen\u001b[1;34m(process_obj)\u001b[0m\n\u001b[0;32m    320\u001b[0m         \u001b[1;32mdef\u001b[0m \u001b[0m_Popen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mprocess_obj\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    321\u001b[0m             \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m\u001b[0mpopen_spawn_win32\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mPopen\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 322\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mPopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mprocess_obj\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    323\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    324\u001b[0m     \u001b[1;32mclass\u001b[0m \u001b[0mSpawnContext\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mBaseContext\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n","\u001b[1;32mc:\\Users\\rlduf\\anaconda3\\envs\\deeplearning\\lib\\multiprocessing\\popen_spawn_win32.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, process_obj)\u001b[0m\n\u001b[0;32m     87\u001b[0m             \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     88\u001b[0m                 \u001b[0mreduction\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdump\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mprep_data\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mto_child\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 89\u001b[1;33m                 \u001b[0mreduction\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdump\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mprocess_obj\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mto_child\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     90\u001b[0m             \u001b[1;32mfinally\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     91\u001b[0m                 \u001b[0mset_spawning_popen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n","\u001b[1;32mc:\\Users\\rlduf\\anaconda3\\envs\\deeplearning\\lib\\multiprocessing\\reduction.py\u001b[0m in \u001b[0;36mdump\u001b[1;34m(obj, file, protocol)\u001b[0m\n\u001b[0;32m     58\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mdump\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfile\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mprotocol\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     59\u001b[0m     \u001b[1;34m'''Replacement for pickle.dump() using ForkingPickler.'''\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 60\u001b[1;33m     \u001b[0mForkingPickler\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfile\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mprotocol\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdump\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     61\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     62\u001b[0m \u001b[1;31m#\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n","\u001b[1;31mPicklingError\u001b[0m: Can't pickle <function <lambda> at 0x000001BA32EAB168>: attribute lookup <lambda> on __main__ failed"]}],"source":["# define EarlyStopping.\n","early_stopper = EarlyStopping(\n","    patience=3, verbose=True, path=os.path.join(log_model_path, \"model.ckpt\")\n",")\n","\n","# do train with validation.\n","train_step = 0\n","for epoch in range(1, max_epoch+1):\n","    # valid step\n","    with torch.no_grad():\n","        val_loss = 0.0\n","        val_corrects = 0\n","        model.eval()\n","\n","        for val_batch_idx, (val_images, val_labels) in enumerate(\n","            tqdm(val_dataloader, position=0, leave=True, desc=\"validation\")\n","        ):\n","            if gpu is not None:\n","                val_images = val_images.cuda(gpu, non_blocking=True)\n","                val_labels = val_labels.cuda(gpu, non_blocking=True)\n","            # forward\n","            val_outputs = model(val_images)\n","            _, val_preds = torch.max(val_outputs, 1)\n","            \n","            # loss & acc\n","            val_loss += loss_function(val_outputs, val_labels) / val_outputs.shape[0]\n","            val_corrects += torch.sum(val_preds == val_labels.data) / val_outputs.shape[0]\n","    \n","    # valid step logging\n","    val_epoch_loss = val_loss / len(val_dataloader)\n","    val_epoch_acc = val_corrects / len(val_dataloader)\n","    \n","    print(\n","        f\"{epoch} epoch, {train_step} step: val_loss: {val_epoch_loss}, val_acc: {val_epoch_acc}\"\n","    )\n","\n","    # tensorboard log\n","    writer.add_scalar(\"Loss/val\", val_epoch_loss, train_step)\n","    writer.add_scalar(\"Acc/val\", val_epoch_acc, train_step)\n","    writer.add_images(\"Images/val\", val_images, train_step)\n","\n","    # wandb log\n","    wandb.log({\n","        \"Loss/val\": val_epoch_loss,\n","        \"Acc/val\": val_epoch_acc,\n","        \"Images/val\": wandb.Image(val_images),\n","        \"Outputs/val\": wandb.Histogram(val_outputs.detach().cpu().numpy()),\n","        \"Preds/val\": wandb.Histogram(val_preds.detach().cpu().numpy()),\n","        \"Labels/val\": wandb.Histogram(val_labels.data.detach().cpu().numpy()),\n","    }, step=train_step)\n","\n","    # check model early stopping point & save model if the model reached the best performance.\n","    early_stopper(val_epoch_loss, model)\n","    if early_stopper.early_stop:\n","        break\n","    \n","    # train step\n","    current_loss = 0\n","    current_corrects = 0\n","    model.train()\n","\n","    for batch_idx, (images, labels) in enumerate(\n","         tqdm(train_dataloader, position=0, leave=True, desc=\"training\")\n","    ):\n","        if gpu is not None:\n","            images = images.cuda(gpu)\n","            labels = labels.cuda(gpu)\n","\n","        current_loss = 0.0\n","        current_corrects = 0\n","\n","        # Forward\n","        # get predictions\n","        outputs = model(images)\n","        _, preds = torch.max(outputs, 1)\n","        \n","        # get loss (Loss 계산)\n","        loss = loss_function(outputs, labels)\n","\n","        # Backpropagation\n","        # optimizer 초기화 (zero화)\n","        optimizer.zero_grad()\n","\n","        # Perform backward pass\n","        loss.backward()\n","\n","        # Perform Optimization\n","        optimizer.step()\n","\n","        # Perform LR scheduler Work\n","        if scheduler is not None:\n","            scheduler.step()\n","\n","        current_loss += loss.item()\n","        current_corrects += torch.sum(preds == labels.data)\n","\n","        if train_step % log_interval == 0:\n","            train_loss = current_loss / log_interval\n","            train_acc = current_corrects / log_interval\n","\n","            print(\n","                f\"{train_step}: train_loss: {train_loss}, train_acc: {train_acc}\"\n","            )\n","            \n","            cur_lr = optimizer.param_groups[0][\"lr\"] if scheduler is None else scheduler.get_last_lr()[0]                \n","\n","            # tensorboard log\n","            writer.add_scalar(\"Loss/train\", train_loss, train_step)\n","            writer.add_scalar(\"Acc/train\", train_acc, train_step)\n","            writer.add_images(\"Images/train\", images, train_step)\n","            writer.add_scalar(\"Learning Rate\", cur_lr, train_step)\n","            writer.add_graph(model, images)\n","\n","            # wandb log\n","            wandb.log({\n","                \"Loss/train\": train_loss,\n","                \"Acc/train\": train_acc,\n","                \"Images/train\": wandb.Image(images),\n","                \"Outputs/train\": wandb.Histogram(outputs.detach().cpu().numpy()),\n","                \"Preds/train\": wandb.Histogram(preds.detach().cpu().numpy()),\n","                \"Labels/train\": wandb.Histogram(labels.data.detach().cpu().numpy()),\n","                \"Learning Rate\": cur_lr,\n","            }, step=train_step)\n","\n","            current_loss = 0\n","            current_corrects = 0\n","\n","        train_step += 1"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ymnDN1VkYOvt"},"outputs":[],"source":["# load model\n","loaded_model = torch.load(os.path.join(log_model_path, \"val_loss-0.02419060841202736-model.ckpt\"))\n","loaded_model.cpu()\n","loaded_model.eval()\n","print(loaded_model)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"AHvB9xAnYWBk"},"outputs":[],"source":["def softmax(x, axis=0):\n","    \"numpy softmax\"\n","    max = np.max(x, axis=axis, keepdims=True)\n","    e_x = np.exp(x - max)\n","    sum = np.sum(e_x, axis=axis, keepdims=True)\n","    f_x = e_x / sum\n","    return f_x"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"_UoTf2ztY7nT"},"outputs":[],"source":["test_batch_size = 100\n","test_dataset = FashionMNIST(data_root, download=True, train=False, transform=transforms.ToTensor())\n","test_dataloader = torch.utils.data.DataLoader(test_dataset, batch_size=test_batch_size, shuffle=False, num_workers=1)\n","\n","test_labels_list = []\n","test_preds_list = []\n","test_outputs_list = []\n","for i, (test_images, test_labels) in enumerate(tqdm(test_dataloader, position=0, leave=True, desc=\"testing\")):\n","    # forward\n","    test_outputs = loaded_model(test_images)\n","    _, test_preds = torch.max(test_outputs, 1)\n","\n","    final_outs = softmax(test_outputs.detach().numpy(), axis=1)\n","    test_outputs_list.extend(final_outs)\n","    test_preds_list.extend(test_preds.detach().numpy())\n","    test_labels_list.extend(test_labels.detach().numpy())\n","\n","test_preds_list = np.array(test_preds_list)\n","test_labels_list = np.array(test_labels_list)\n","\n","print(f\"\\nacc: {np.mean(test_preds_list == test_labels_list)*100}%\")"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"M0a4PPefaRfH"},"outputs":[],"source":["# ROC Curve\n","from sklearn.metrics import roc_curve\n","from sklearn.metrics import roc_auc_score\n","\n","fpr = {}\n","tpr = {}\n","thresh = {}\n","n_class = 10\n","\n","for i in range(n_class):\n","    fpr[i], tpr[i], thresh[i] = roc_curve(test_labels_list, np.array(test_outputs_list)[:, i], pos_label=i)\n","\n","# plot.\n","for i in range(n_class):\n","    plt.plot(fpr[i], tpr[i], linestyle=\"--\", label=f\"Class {i} vs Rest\")\n","plt.title(\"Multi-class ROC Curve\")\n","plt.xlabel(\"False Positive Rate\")\n","plt.ylabel(\"True Positive Rate\")\n","plt.legend(loc=\"best\")\n","plt.show()\n","\n","print(\"auc_score\", roc_auc_score(test_labels_list, test_outputs_list, multi_class=\"ovo\", average=\"macro\"))"]}],"metadata":{"accelerator":"GPU","colab":{"authorship_tag":"ABX9TyNV8I4xg9IlpnHojmJVgHse","collapsed_sections":[],"mount_file_id":"1gNh-HsjMOM_aMXda7EfQdjZjqAA3DNqt","name":"05-2. Efficient Net Fine-tune","private_outputs":true,"provenance":[{"file_id":"1Z45RhZD6DFfZgDsoSGZhYKoAhgf4szLf","timestamp":1628427684925},{"file_id":"1vOwqGgv4OKk-1vYWcH8uFpvoIooaUeTj","timestamp":1628424146619},{"file_id":"1n37-PsBNU1tEXNwUvWohvHVJD81-C8m2","timestamp":1627212638626},{"file_id":"1gNh-HsjMOM_aMXda7EfQdjZjqAA3DNqt","timestamp":1626696451891}]},"kernelspec":{"display_name":"jupyter_notebook","language":"python","name":"deeplearning"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.16"}},"nbformat":4,"nbformat_minor":0}
