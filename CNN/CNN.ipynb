{"cells":[{"attachments":{},"cell_type":"markdown","metadata":{"id":"KJT5kqyZGe1p"},"source":["# Convolutional Neural Network"]},{"attachments":{},"cell_type":"markdown","metadata":{"id":"NzHP2rndF-0G"},"source":["## import"]},{"cell_type":"code","execution_count":1,"metadata":{"id":"Mi95dewjGeW_"},"outputs":[],"source":["import os\n","import sys\n","from datetime import datetime\n","\n","project_root = \"C:/Users/rlduf/.vscode/DeepLearning\" # 경로 설정\n","sys.path.append(project_root)"]},{"cell_type":"code","execution_count":2,"metadata":{"id":"YD7vyST9GdHv"},"outputs":[],"source":["import numpy as np\n","from tqdm import tqdm\n","import matplotlib.pyplot as plt\n","from omegaconf import OmegaConf # configuration 관리\n","from omegaconf import DictConfig\n","\n","import torch\n","from torch import nn\n","import torch.nn.functional as F\n","from torch import optim\n","from torch_optimizer import RAdam\n","from torch_optimizer import AdamP\n","from torch.utils.tensorboard import SummaryWriter\n","from torch.utils.data import random_split\n","from torchvision.datasets import FashionMNIST\n","from torchvision import transforms\n","import wandb"]},{"cell_type":"code","execution_count":3,"metadata":{"id":"QX3soatAMk5B"},"outputs":[],"source":["from data_utils import dataset_split"]},{"cell_type":"code","execution_count":4,"metadata":{"id":"lISGUqfUG_Ny"},"outputs":[],"source":["data_root = os.path.join(os.getcwd(), \"data\")\n","\n","# 전처리 부분 (preprocessing) & 데이터 셋 정의.\n","transform = transforms.Compose(\n","    [\n","        transforms.ToTensor(),\n","        transforms.Normalize([0.5], [0.5]), # mean, # std\n","    ]\n",")\n","fashion_mnist_dataset = FashionMNIST(data_root, download=True, train=True, transform=transform)\n"]},{"attachments":{},"cell_type":"markdown","metadata":{"id":"0waoPp23NcE0"},"source":["## Dataloader"]},{"cell_type":"code","execution_count":5,"metadata":{"id":"A5Nq1tZiJ84g"},"outputs":[],"source":["datasets = dataset_split(fashion_mnist_dataset, split=[0.9, 0.1])\n","\n","train_dataset = datasets[\"train\"]\n","val_dataset = datasets[\"val\"]\n","\n","train_batch_size = 100\n","val_batch_size = 10\n","\n","train_dataloader = torch.utils.data.DataLoader(\n","    train_dataset, batch_size=train_batch_size, shuffle=True, num_workers=1\n",")\n","val_dataloader = torch.utils.data.DataLoader(\n","    val_dataset, batch_size=val_batch_size, shuffle=False, num_workers=1\n",")"]},{"attachments":{},"cell_type":"markdown","metadata":{"id":"Lwd5nW_3N37z"},"source":["## MLP model\n"]},{"cell_type":"code","execution_count":6,"metadata":{"id":"-O--VMLMN04F"},"outputs":[],"source":["# Define Model.\n","\n","class MLP(nn.Module):\n","    def __init__(self, in_dim: int, h1_dim: int, h2_dim: int, out_dim: int):\n","        super().__init__()\n","        self.linear1 = nn.Linear(in_dim, h1_dim)\n","        self.linear2 = nn.Linear(h1_dim, h2_dim)\n","        self.linear3 = nn.Linear(h2_dim, out_dim)\n","        self.relu = F.relu\n","    \n","    def forward(self, input):\n","        x = torch.flatten(input, start_dim=1)\n","        x = self.relu(self.linear1(x))\n","        x = self.relu(self.linear2(x))\n","        out = self.linear3(x)\n","        # out = F.softmax(out)\n","        return out\n","\n","class MLPWithDropout(MLP):\n","    def __init__(self, in_dim: int, h1_dim: int, h2_dim: int, out_dim: int, dropout_prob: float):\n","        super().__init__(in_dim, h1_dim, h2_dim, out_dim)\n","        self.dropout1 = nn.Dropout(dropout_prob)\n","        self.dropout2 = nn.Dropout(dropout_prob)\n","    \n","    def forward(self, input):\n","        x = torch.flatten(input, start_dim=1)\n","        x = self.relu(self.linear1(x))\n","        x = self.dropout1(x)\n","        x = self.relu(self.linear2(x))\n","        x = self.dropout2(x)\n","        out = self.linear3(x)\n","        # out = F.softmax(out)\n","        return out"]},{"attachments":{},"cell_type":"markdown","metadata":{"id":"42in1xpAqQDY"},"source":["## CNN model"]},{"cell_type":"code","execution_count":7,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["layer_1:\n","  conv2d_in_channels: 1\n","  conv2d_out_channels: 32\n","  conv2d_kernel_size: 3\n","  conv2d_padding: 1\n","  maxpool2d_kernel_size: 2\n","  maxpool2d_stride: 2\n","layer_2:\n","  conv2d_in_channels: 32\n","  conv2d_out_channels: 64\n","  conv2d_kernel_size: 3\n","  conv2d_padding: 0\n","  maxpool2d_kernel_size: 2\n","  maxpool2d_stride: 1\n","fc_1:\n","  in_features: 7744\n","  out_features: 512\n","fc_2:\n","  in_features: 512\n","  out_features: 128\n","fc_3:\n","  in_features: 128\n","  out_features: 10\n","dropout_prob: 0.25\n","\n"]}],"source":["# 모델의 configuration을 정의\n","# 추후에 configuration의 수정과 tuning이 쉬움\n","_cnn_cfg_dict: dict = {\n","    \"layer_1\": {\n","        \"conv2d_in_channels\": 1,\n","        \"conv2d_out_channels\": 32,\n","        \"conv2d_kernel_size\": 3,\n","        \"conv2d_padding\": 1,\n","        \"maxpool2d_kernel_size\": 2,\n","        \"maxpool2d_stride\": 2,\n","    },\n","    \"layer_2\": {\n","        \"conv2d_in_channels\": 32,\n","        \"conv2d_out_channels\": 64,\n","        \"conv2d_kernel_size\": 3,\n","        \"conv2d_padding\": 0,\n","        \"maxpool2d_kernel_size\": 2,\n","        \"maxpool2d_stride\": 1,\n","    },\n","    \"fc_1\": {\n","        \"in_features\": 7744, #  수정 필요!\n","        \"out_features\": 512,\n","    },\n","    \"fc_2\": {\n","        \"in_features\": 512,\n","        \"out_features\": 128,        \n","    },\n","    \"fc_3\": {\n","        \"in_features\": 128,\n","        \"out_features\": 10,\n","    },\n","    \"dropout_prob\": 0.25,\n","}\n","_cnn_cfg = OmegaConf.create(_cnn_cfg_dict) # configuration 생성\n","print(OmegaConf.to_yaml(_cnn_cfg))"]},{"cell_type":"code","execution_count":8,"metadata":{"id":"dCEx_VgEqTiB"},"outputs":[{"data":{"text/plain":["CNN(\n","  (layer1): Sequential(\n","    (0): Conv2d(1, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","    (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","    (2): ReLU()\n","    (3): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n","  )\n","  (layer2): Sequential(\n","    (0): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1))\n","    (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","    (2): ReLU()\n","    (3): MaxPool2d(kernel_size=2, stride=1, padding=0, dilation=1, ceil_mode=False)\n","  )\n","  (fc1): Linear(in_features=7744, out_features=512, bias=True)\n","  (fc2): Linear(in_features=512, out_features=128, bias=True)\n","  (fc3): Linear(in_features=128, out_features=10, bias=True)\n","  (dropout): Dropout2d(p=0.25, inplace=False)\n",")"]},"execution_count":8,"metadata":{},"output_type":"execute_result"}],"source":["class CNN(nn.Module):\n","    def __init__(self, cfg: DictConfig = _cnn_cfg):\n","        super().__init__()\n","        self.layer1 = nn.Sequential(\n","            nn.Conv2d(\n","                in_channels=cfg.layer_1.conv2d_in_channels,\n","                out_channels=cfg.layer_1.conv2d_out_channels,\n","                kernel_size=cfg.layer_1.conv2d_kernel_size,\n","                padding=cfg.layer_1.conv2d_padding\n","            ),\n","            nn.BatchNorm2d(cfg.layer_1.conv2d_out_channels),\n","            nn.ReLU(),\n","            nn.MaxPool2d(\n","                kernel_size=cfg.layer_1.maxpool2d_kernel_size,\n","                stride=cfg.layer_1.maxpool2d_stride\n","            )\n","        )\n","        self.layer2 = nn.Sequential(\n","            nn.Conv2d(\n","                in_channels=cfg.layer_2.conv2d_in_channels,\n","                out_channels=cfg.layer_2.conv2d_out_channels,\n","                kernel_size=cfg.layer_2.conv2d_kernel_size,\n","                padding=cfg.layer_2.conv2d_padding\n","            ),\n","            nn.BatchNorm2d(cfg.layer_2.conv2d_out_channels),\n","            nn.ReLU(),\n","            nn.MaxPool2d(\n","                kernel_size=cfg.layer_2.maxpool2d_kernel_size,\n","                stride=cfg.layer_2.maxpool2d_stride\n","            )\n","        )\n","        self.fc1 = nn.Linear(\n","            in_features=cfg.fc_1.in_features,\n","            out_features=cfg.fc_1.out_features,\n","        )\n","        self.fc2 = nn.Linear(\n","            in_features=cfg.fc_2.in_features,\n","            out_features=cfg.fc_2.out_features,\n","        )\n","        self.fc3 = nn.Linear(\n","            in_features=cfg.fc_3.in_features,\n","            out_features=cfg.fc_3.out_features,\n","        )\n","        self.dropout = nn.Dropout2d(cfg.dropout_prob)\n","\n","\n","    def forward(self, x):\n","        out = self.layer1(x)\n","        out = self.layer2(out)\n","        out = out.view(out.size(0), -1) # batchsize를 제외하고 나머지는 flatten\n","        out = self.fc1(out)\n","        out = self.dropout(out)\n","        out = self.fc2(out)\n","        out = self.fc3(out)\n","        return out\n","    \n","CNN()"]},{"cell_type":"markdown","metadata":{"id":"tMM1y75wql8f"},"source":["## Learning Rate Scheduler \n","\n"]},{"cell_type":"code","execution_count":9,"metadata":{"id":"3y1m5T3-qqCk"},"outputs":[],"source":["# Warmup Scheduler\n","class WarmupLR(optim.lr_scheduler.LambdaLR):\n","\n","    def __init__(\n","        self,\n","        optimizer: optim.Optimizer,\n","        warmup_end_steps: int,\n","        last_epoch: int = -1,\n","    ):\n","        \n","        def wramup_fn(step: int):\n","            if step < warmup_end_steps:\n","                return float(step) / float(max(warmup_end_steps, 1))\n","            return 1.0\n","        \n","        super().__init__(optimizer, wramup_fn, last_epoch)\n"]},{"attachments":{},"cell_type":"markdown","metadata":{"id":"b8tljBSaQBZB"},"source":["## Loss function, Optimizer, Logger"]},{"cell_type":"code","execution_count":10,"metadata":{"id":"z8p_hsjsO-on"},"outputs":[{"name":"stderr","output_type":"stream","text":["Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n","\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mrlduf422\u001b[0m (use `wandb login --relogin` to force relogin)\n","\u001b[34m\u001b[1mwandb\u001b[0m: wandb version 0.14.0 is available!  To upgrade, please run:\n","\u001b[34m\u001b[1mwandb\u001b[0m:  $ pip install wandb --upgrade\n"]},{"data":{"text/html":["\n","                Tracking run with wandb version 0.11.1<br/>\n","                Syncing run <strong style=\"color:#cdcd00\">2023-03-29T15:35:18-CNN-RAdam_optim_0.001_lr_with_no_scheduler</strong> to <a href=\"https://wandb.ai\" target=\"_blank\">Weights & Biases</a> <a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">(Documentation)</a>.<br/>\n","                Project page: <a href=\"https://wandb.ai/rlduf422/fashion_mnist_CNN\" target=\"_blank\">https://wandb.ai/rlduf422/fashion_mnist_CNN</a><br/>\n","                Run page: <a href=\"https://wandb.ai/rlduf422/fashion_mnist_CNN/runs/b27x7g29\" target=\"_blank\">https://wandb.ai/rlduf422/fashion_mnist_CNN/runs/b27x7g29</a><br/>\n","                Run data is saved locally in <code>c:\\Users\\rlduf\\.vscode\\DeepLearning\\CNN\\wandb\\run-20230329_153518-b27x7g29</code><br/><br/>\n","            "],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"}],"source":["# gpu setup\n","# gpu = None\n","gpu = 0\n","\n","# define model.\n","# model = MLP(28*28, 128, 64, 10)\n","# model = MLPWithDropout(28*28, 128, 64, 10, dropout_prob=0.3)\n","model = CNN(cfg=_cnn_cfg)\n","if gpu is not None:\n","    model.cuda(gpu)\n","model_name = type(model).__name__\n","\n","# define loss\n","loss_function = nn.CrossEntropyLoss()\n","\n","# define optimizer\n","lr = 1e-3\n","# optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n","# optimizer = torch.optim.SGD(model.parameters(), lr=lr)\n","optimizer = RAdam(model.parameters(), lr=lr)\n","# optimizer = AdamP(model.parameters(), lr=lr)\n","optimizer_name = type(optimizer).__name__\n","\n","# define scheduler\n","scheduler = None\n","# scheduler = WarmupLR(optimizer, 1500)\n","scheduler_name = type(scheduler).__name__ if scheduler is not None else \"no\"\n","\n","max_epoch = 50\n","\n","# define tensorboard logger\n","run_name = f\"{datetime.now().isoformat(timespec='seconds')}-{model_name}-{optimizer_name}_optim_{lr}_lr_with_{scheduler_name}_scheduler\"\n","run_dirname = \"cnn-fashion-mnist\"\n","log_dir = os.path.join(project_root)\n","writer = SummaryWriter(log_dir)\n","log_interval = 100\n","\n","# define wandb\n","project_name = \"fashion_mnist_CNN\"\n","run_tags = [project_name]\n","wandb.init(\n","    project=project_name,\n","    name=run_name,\n","    tags=run_tags,\n","    config={\"lr\": lr, \"model_name\": model_name, \"optimizer_name\": optimizer_name, \"scheduler_name\": scheduler_name},\n","    reinit=True,\n",")\n","wandb.watch(model)\n","\n","# set save model path\n","log_model_path = os.path.join(log_dir, \"models\")\n","os.makedirs(log_model_path, exist_ok=True)\n"]},{"attachments":{},"cell_type":"markdown","metadata":{"id":"lnGxA90KyyUi"},"source":["## Early Stopping callback Object Class"]},{"cell_type":"code","execution_count":11,"metadata":{"id":"WyuzST93ynLE"},"outputs":[],"source":["# With some modifications, source is from https://github.com/Bjarten/early-stopping-pytorch\n","\n","class EarlyStopping:\n","    \"\"\"Early stops the training if validation loss doesn't improve after a given patience.\"\"\"\n","    def __init__(self, patience=7, verbose=False, delta=0, path='checkpoint.ckpt', trace_func=print):\n","        \"\"\"\n","        Args:\n","            patience (int): How long to wait after last time validation loss improved.\n","                            Default: 7\n","            verbose (bool): If True, prints a message for each validation loss improvement. \n","                            Default: False\n","            delta (float): Minimum change in the monitored quantity to qualify as an improvement.\n","                            Default: 0\n","            path (str): Path for the checkpoint to be saved to.\n","                            Default: 'checkpoint.ckpt'\n","            trace_func (function): trace print function.\n","                            Default: print            \n","        \"\"\"\n","        self.patience = patience\n","        self.verbose = verbose\n","        self.counter = 0\n","        self.best_score = None\n","        self.early_stop = False\n","        self.val_loss_min = np.Inf\n","        self.delta = delta\n","        self.path = path\n","        self.trace_func = trace_func\n","\n","    def __call__(self, val_loss, model):\n","\n","        score = -val_loss\n","\n","        if self.best_score is None:\n","            self.best_score = score\n","            self.save_checkpoint(val_loss, model)\n","        elif score < self.best_score + self.delta:\n","            self.counter += 1\n","            self.trace_func(f'EarlyStopping counter: {self.counter} out of {self.patience}')\n","            if self.counter >= self.patience:\n","                self.early_stop = True\n","        else:\n","            self.best_score = score\n","            self.save_checkpoint(val_loss, model)\n","            self.counter = 0\n","\n","    def save_checkpoint(self, val_loss, model):\n","        '''Saves model when validation loss decrease.'''\n","        if self.verbose:\n","            self.trace_func(f'Validation loss decreased ({self.val_loss_min:.6f} --> {val_loss:.6f}).  Saving model ...')\n","        \n","        filename = self.path.split('/')[-1]\n","        save_dir = os.path.dirname(self.path)\n","        torch.save(model, os.path.join(save_dir, f\"val_loss-{val_loss}-{filename}\"))\n","        self.val_loss_min = val_loss"]},{"cell_type":"code","execution_count":12,"metadata":{"id":"oq-XpcGXQu1v"},"outputs":[{"data":{"text/html":["\n","      <iframe id=\"tensorboard-frame-d62c2549e60533b3\" width=\"100%\" height=\"800\" frameborder=\"0\">\n","      </iframe>\n","      <script>\n","        (function() {\n","          const frame = document.getElementById(\"tensorboard-frame-d62c2549e60533b3\");\n","          const url = new URL(\"http://localhost\");\n","          const port = 6006;\n","          if (port) {\n","            url.port = port;\n","          }\n","          frame.src = url;\n","        })();\n","      </script>\n","    "],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["validation:   0%|          | 0/600 [00:00<?, ?it/s]c:\\Users\\rlduf\\anaconda3\\envs\\deeplearning\\lib\\site-packages\\torch\\nn\\functional.py:1331: UserWarning: dropout2d: Received a 2-D input to dropout2d, which is deprecated and will result in an error in a future release. To retain the behavior and silence this warning, please use dropout instead. Note that dropout2d exists to provide channel-wise dropout on inputs with 2 spatial dimensions, a channel dimension, and an optional batch dimension (i.e. 3D or 4D inputs).\n","  warnings.warn(warn_msg)\n","validation: 100%|██████████| 600/600 [00:03<00:00, 159.53it/s]\n"]},{"name":"stdout","output_type":"stream","text":["1 epoch, 0 step: val_loss: 0.23065419495105743, val_acc: 0.06466667354106903\n","Validation loss decreased (inf --> 0.230654).  Saving model ...\n"]},{"ename":"RuntimeError","evalue":"File C:/Users/rlduf/.vscode/DeepLearning\\models\\val_loss-0.23065419495105743-DeepLearning\\models\\model.ckpt cannot be opened.","output_type":"error","traceback":["\u001b[1;31m---------------------------------------------------------------------------\u001b[0m","\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)","\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_13032\\2959138437.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     54\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     55\u001b[0m     \u001b[1;31m# check model early stopping point & save model if the model reached the best performance.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 56\u001b[1;33m     \u001b[0mearly_stopper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mval_epoch_loss\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     57\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mearly_stopper\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mearly_stop\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     58\u001b[0m         \u001b[1;32mbreak\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n","\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_13032\\4101339322.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, val_loss, model)\u001b[0m\n\u001b[0;32m     33\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbest_score\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     34\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbest_score\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mscore\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 35\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msave_checkpoint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mval_loss\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     36\u001b[0m         \u001b[1;32melif\u001b[0m \u001b[0mscore\u001b[0m \u001b[1;33m<\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbest_score\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdelta\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     37\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcounter\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n","\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_13032\\4101339322.py\u001b[0m in \u001b[0;36msave_checkpoint\u001b[1;34m(self, val_loss, model)\u001b[0m\n\u001b[0;32m     51\u001b[0m         \u001b[0mfilename\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'/'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     52\u001b[0m         \u001b[0msave_dir\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdirname\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 53\u001b[1;33m         \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msave\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msave_dir\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34mf\"val_loss-{val_loss}-{filename}\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     54\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mval_loss_min\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mval_loss\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n","\u001b[1;32mc:\\Users\\rlduf\\anaconda3\\envs\\deeplearning\\lib\\site-packages\\torch\\serialization.py\u001b[0m in \u001b[0;36msave\u001b[1;34m(obj, f, pickle_module, pickle_protocol, _use_new_zipfile_serialization)\u001b[0m\n\u001b[0;32m    420\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    421\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0m_use_new_zipfile_serialization\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 422\u001b[1;33m         \u001b[1;32mwith\u001b[0m \u001b[0m_open_zipfile_writer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mf\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mopened_zipfile\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    423\u001b[0m             \u001b[0m_save\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mopened_zipfile\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpickle_module\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpickle_protocol\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    424\u001b[0m             \u001b[1;32mreturn\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n","\u001b[1;32mc:\\Users\\rlduf\\anaconda3\\envs\\deeplearning\\lib\\site-packages\\torch\\serialization.py\u001b[0m in \u001b[0;36m_open_zipfile_writer\u001b[1;34m(name_or_buffer)\u001b[0m\n\u001b[0;32m    307\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    308\u001b[0m         \u001b[0mcontainer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_open_zipfile_writer_buffer\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 309\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mcontainer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mname_or_buffer\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    310\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    311\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n","\u001b[1;32mc:\\Users\\rlduf\\anaconda3\\envs\\deeplearning\\lib\\site-packages\\torch\\serialization.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, name)\u001b[0m\n\u001b[0;32m    285\u001b[0m \u001b[1;32mclass\u001b[0m \u001b[0m_open_zipfile_writer_file\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0m_opener\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    286\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__init__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m->\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 287\u001b[1;33m         \u001b[0msuper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0m_open_zipfile_writer_file\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_C\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mPyTorchFileWriter\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    288\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    289\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__exit__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m->\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n","\u001b[1;31mRuntimeError\u001b[0m: File C:/Users/rlduf/.vscode/DeepLearning\\models\\val_loss-0.23065419495105743-DeepLearning\\models\\model.ckpt cannot be opened."]}],"source":["%load_ext tensorboard\n","%tensorboard --logdir C:/Users/rlduf/.vscode/DeepLearning/runs\n","\n","# define EarlyStopping.\n","early_stopper = EarlyStopping(\n","    patience=3, verbose=True, path=os.path.join(log_model_path, \"model.ckpt\")\n",")\n","\n","# do train with validation.\n","train_step = 0\n","for epoch in range(1, max_epoch+1):\n","    # valid step\n","    with torch.no_grad():\n","        val_loss = 0.0\n","        val_corrects = 0\n","        model.eval()\n","\n","        for val_batch_idx, (val_images, val_labels) in enumerate(\n","            tqdm(val_dataloader, position=0, leave=True, desc=\"validation\")\n","        ):\n","            if gpu is not None:\n","                val_images = val_images.cuda(gpu, non_blocking=True)\n","                val_labels = val_labels.cuda(gpu, non_blocking=True)\n","            # forward\n","            val_outputs = model(val_images)\n","            _, val_preds = torch.max(val_outputs, 1)\n","            \n","            # loss & acc\n","            val_loss += loss_function(val_outputs, val_labels) / val_outputs.shape[0]\n","            val_corrects += torch.sum(val_preds == val_labels.data) / val_outputs.shape[0]\n","    \n","    # valid step logging\n","    val_epoch_loss = val_loss / len(val_dataloader)\n","    val_epoch_acc = val_corrects / len(val_dataloader)\n","    \n","    print(\n","        f\"{epoch} epoch, {train_step} step: val_loss: {val_epoch_loss}, val_acc: {val_epoch_acc}\"\n","    )\n","\n","    # tensorboard log\n","    writer.add_scalar(\"Loss/val\", val_epoch_loss, train_step)\n","    writer.add_scalar(\"Acc/val\", val_epoch_acc, train_step)\n","    writer.add_images(\"Images/val\", val_images, train_step)\n","\n","    # wandb log\n","    wandb.log({\n","        \"Loss/val\": val_epoch_loss,\n","        \"Acc/val\": val_epoch_acc,\n","        \"Images/val\": wandb.Image(val_images),\n","        \"Outputs/val\": wandb.Histogram(val_outputs.detach().cpu().numpy()),\n","        \"Preds/val\": wandb.Histogram(val_preds.detach().cpu().numpy()),\n","        \"Labels/val\": wandb.Histogram(val_labels.data.detach().cpu().numpy()),\n","    }, step=train_step)\n","\n","    # check model early stopping point & save model if the model reached the best performance.\n","    early_stopper(val_epoch_loss, model)\n","    if early_stopper.early_stop:\n","        break\n","    \n","    # train step\n","    current_loss = 0\n","    current_corrects = 0\n","    model.train()\n","\n","    for batch_idx, (images, labels) in enumerate(\n","         tqdm(train_dataloader, position=0, leave=True, desc=\"training\")\n","    ):\n","        if gpu is not None:\n","            images = images.cuda(gpu)\n","            labels = labels.cuda(gpu)\n","\n","        current_loss = 0.0\n","        current_corrects = 0\n","\n","        # Forward\n","        # get predictions\n","        outputs = model(images)\n","        _, preds = torch.max(outputs, 1)\n","        \n","        # get loss (Loss 계산)\n","        loss = loss_function(outputs, labels)\n","\n","        # Backpropagation\n","        # optimizer 초기화 (zero화)\n","        optimizer.zero_grad()\n","\n","        # Perform backward pass\n","        loss.backward()\n","\n","        # Perform Optimization\n","        optimizer.step()\n","\n","        # Perform LR scheduler Work\n","        if scheduler is not None:\n","            scheduler.step()\n","\n","        current_loss += loss.item()\n","        current_corrects += torch.sum(preds == labels.data)\n","\n","        if train_step % log_interval == 0:\n","            train_loss = current_loss / log_interval\n","            train_acc = current_corrects / log_interval\n","\n","            print(\n","                f\"{train_step}: train_loss: {train_loss}, train_acc: {train_acc}\"\n","            )\n","            \n","            cur_lr = optimizer.param_groups[0][\"lr\"] if scheduler is None else scheduler.get_last_lr()[0]                \n","\n","            # tensorboard log\n","            writer.add_scalar(\"Loss/train\", train_loss, train_step)\n","            writer.add_scalar(\"Acc/train\", train_acc, train_step)\n","            writer.add_images(\"Images/train\", images, train_step)\n","            writer.add_scalar(\"Learning Rate\", cur_lr, train_step)\n","            writer.add_graph(model, images)\n","\n","            # wandb log\n","            wandb.log({\n","                \"Loss/train\": train_loss,\n","                \"Acc/train\": train_acc,\n","                \"Images/train\": wandb.Image(images),\n","                \"Outputs/train\": wandb.Histogram(outputs.detach().cpu().numpy()),\n","                \"Preds/train\": wandb.Histogram(preds.detach().cpu().numpy()),\n","                \"Labels/train\": wandb.Histogram(labels.data.detach().cpu().numpy()),\n","                \"Learning Rate\": cur_lr,\n","            }, step=train_step)\n","\n","            current_loss = 0\n","            current_corrects = 0\n","\n","        train_step += 1"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ymnDN1VkYOvt"},"outputs":[],"source":["# load model\n","loaded_model = torch.load(os.path.join(log_model_path, \"val_loss-0.02419060841202736-model.ckpt\"))\n","loaded_model.eval()\n","loaded_model.cpu()\n","print(loaded_model)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"AHvB9xAnYWBk"},"outputs":[],"source":["def softmax(x, axis=0):\n","    \"numpy softmax\"\n","    max = np.max(x, axis=axis, keepdims=True)\n","    e_x = np.exp(x - max)\n","    sum = np.sum(e_x, axis=axis, keepdims=True)\n","    f_x = e_x / sum\n","    return f_x"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"_UoTf2ztY7nT"},"outputs":[],"source":["test_batch_size = 100\n","test_dataset = FashionMNIST(data_root, download=True, train=False, transform=transforms.ToTensor())\n","test_dataloader = torch.utils.data.DataLoader(test_dataset, batch_size=test_batch_size, shuffle=False, num_workers=1)\n","\n","test_labels_list = []\n","test_preds_list = []\n","test_outputs_list = []\n","for i, (test_images, test_labels) in enumerate(tqdm(test_dataloader, position=0, leave=True, desc=\"testing\")):\n","    # forward\n","    test_outputs = loaded_model(test_images)\n","    _, test_preds = torch.max(test_outputs, 1)\n","\n","    final_outs = softmax(test_outputs.detach().numpy(), axis=1)\n","    test_outputs_list.extend(final_outs)\n","    test_preds_list.extend(test_preds.detach().numpy())\n","    test_labels_list.extend(test_labels.detach().numpy())\n","\n","test_preds_list = np.array(test_preds_list)\n","test_labels_list = np.array(test_labels_list)\n","\n","print(f\"\\nacc: {np.mean(test_preds_list == test_labels_list)*100}%\")"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"M0a4PPefaRfH"},"outputs":[],"source":["# ROC Curve\n","from sklearn.metrics import roc_curve\n","from sklearn.metrics import roc_auc_score\n","\n","fpr = {}\n","tpr = {}\n","thresh = {}\n","n_class = 10\n","\n","for i in range(n_class):\n","    fpr[i], tpr[i], thresh[i] = roc_curve(test_labels_list, np.array(test_outputs_list)[:, i], pos_label=i)\n","\n","# plot.\n","for i in range(n_class):\n","    plt.plot(fpr[i], tpr[i], linestyle=\"--\", label=f\"Class {i} vs Rest\")\n","plt.title(\"Multi-class ROC Curve\")\n","plt.xlabel(\"False Positive Rate\")\n","plt.ylabel(\"True Positive Rate\")\n","plt.legend(loc=\"best\")\n","plt.show()\n","\n","print(\"auc_score\", roc_auc_score(test_labels_list, test_outputs_list, multi_class=\"ovo\", average=\"macro\"))"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Dm5jZ7urbMAO"},"outputs":[],"source":[]}],"metadata":{"accelerator":"GPU","colab":{"authorship_tag":"ABX9TyO/OGHsxyYuDm3U7bgw1OZs","collapsed_sections":[],"mount_file_id":"1gNh-HsjMOM_aMXda7EfQdjZjqAA3DNqt","name":"05-1. CNN","private_outputs":true,"provenance":[{"file_id":"1vOwqGgv4OKk-1vYWcH8uFpvoIooaUeTj","timestamp":1628424146619},{"file_id":"1n37-PsBNU1tEXNwUvWohvHVJD81-C8m2","timestamp":1627212638626},{"file_id":"1gNh-HsjMOM_aMXda7EfQdjZjqAA3DNqt","timestamp":1626696451891}]},"kernelspec":{"display_name":"jupyter notebook","language":"python","name":"deeplearning"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.16"}},"nbformat":4,"nbformat_minor":0}
